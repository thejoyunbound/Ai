{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4a0147c-74ab-480a-a186-1117c2bb66b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt, Kkma, Komoran\n",
    "from tensorflow.keras.utils import pad_sequences, to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "127fac95-1e5a-4057-8648-b8260bb38919",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('kedi.csv',encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "224d8691-8161-417e-be2a-0b18826780aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#독립변수, 종속변수\n",
    "X = df.프로그램명\n",
    "y = df.소분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbb5f5b7-0a15-4a6d-88d3-838e5eddedf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 형태소 분석기 \n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1273863b-5422-457e-bca0-1591feb29ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.apply(okt.nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0e63881-8352-4eb5-9976-b89bf7a862bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 문자를 숫자로 바꾸는 작업\n",
    "# 1. 유니크한 값을 정리\n",
    "word_list_x = []\n",
    "for x in X:\n",
    "    word_list_x.extend(x)\n",
    "word_list_x = list(set(word_list_x))\n",
    "# 2. index_word 구성된 딕셔너리 작성 (dictionary comprehention)\n",
    "index_word_x = { i+1:v for i,v in enumerate(word_list_x)}\n",
    "# 3. word_index 구성된 딕셔너리 작성\n",
    "word_index_x = { v:i for i,v in index_word_x.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7636175a-a4bf-411c-8fe3-f2793f4d0265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word들을 정수로 변환\n",
    "def trans_word_index(x):\n",
    "    tmp = []\n",
    "    for i in x:\n",
    "        tmp.append(word_index_x[i])\n",
    "    return tmp\n",
    "def trans_index_word(x):\n",
    "    tmp = []\n",
    "    for i in x:\n",
    "        tmp.append(index_word_x[i])\n",
    "        return tmp\n",
    "\n",
    "X_ = X.apply(trans_word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7673067-f090-4bf1-b8ea-21b5990c525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = X_.apply(len).max()\n",
    "X_ = X_.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f149885d-9b4e-46b6-b14f-398caa5b5091",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = pad_sequences(X_,maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b32a706b-33c7-4982-a0bc-785b759757e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list_y = []\n",
    "for i in y:\n",
    "    word_list_y.extend([i])\n",
    "word_list_y = list(set(word_list_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc587f2a-83bd-4a50-81ec-bcf6b2e6258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word_y = { i:v for i, v in enumerate(word_list_y)}\n",
    "word_index_y = { v:i for i,v in index_word_y.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa337f97-65ba-4294-b875-472de5ffbc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_y(x):\n",
    "    return word_index_y[x]\n",
    "y_ = y.apply(trans_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "164ee8f7-30aa-4536-813b-79f725679cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = to_categorical(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be7370cc-d35a-4714-bacc-e7ae75dfbc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((125170, 21), (125170, 117))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_.shape, y_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ab93d85-865e-4301-87e5-bf3949800935",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델 생성을 위한 모듈 import\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten\n",
    "from tensorflow.keras.layers import Dense, LSTM, BatchNormalization, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ec63365-c2ab-40ae-9c85-ca43d4f68e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## input dimension 계산\n",
    "input_dim = max(word_index_x.values())+1\n",
    "## 벡터의 길이 계산\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2730f125-8fcd-49ed-b915-36c8aa92e13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모델 생성\n",
    "model = Sequential(\n",
    "    [\n",
    "        Embedding(input_dim,200,input_length=maxlen),\n",
    "        LSTM(32,return_sequences=True),\n",
    "        BatchNormalization(),\n",
    "        LSTM(64,return_sequences=True),\n",
    "        BatchNormalization(),\n",
    "        Flatten(),\n",
    "        Dense(256,activation='relu'),\n",
    "        Dense(117)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f190cf4-f039-477f-91a1-ea9e9b811155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 21, 200)           3341200   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 21, 32)            29824     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 21, 32)           128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 21, 64)            24832     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 21, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1344)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               344320    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 117)               30069     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,770,629\n",
      "Trainable params: 3,770,437\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa18ff90-9c83-4d50-b0cc-a5f95f1f7504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f108031-df0a-4c19-a97c-19ca12a17103",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_,y_,test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10cf364b-b088-4ed1-8612-071ee4c4495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "77dc66ea-f23f-4fdb-93af-38c19dbf667f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3130/3130 [==============================] - 214s 64ms/step - loss: 11.2149 - accuracy: 0.1370 - val_loss: 9.6326 - val_accuracy: 0.1409\n",
      "Epoch 2/10\n",
      "3130/3130 [==============================] - 138s 44ms/step - loss: 11.7067 - accuracy: 0.1422 - val_loss: 12.1479 - val_accuracy: 0.1412\n",
      "Epoch 3/10\n",
      "3130/3130 [==============================] - 153s 49ms/step - loss: 11.9713 - accuracy: 0.1418 - val_loss: 12.4496 - val_accuracy: 0.1412\n",
      "Epoch 4/10\n",
      "3130/3130 [==============================] - 153s 49ms/step - loss: 11.7389 - accuracy: 0.1435 - val_loss: 10.9786 - val_accuracy: 0.1426\n",
      "Epoch 5/10\n",
      "3130/3130 [==============================] - 149s 48ms/step - loss: 11.6484 - accuracy: 0.1431 - val_loss: 11.0723 - val_accuracy: 0.1487\n",
      "Epoch 6/10\n",
      "3130/3130 [==============================] - 150s 48ms/step - loss: 11.5189 - accuracy: 0.1480 - val_loss: 10.3738 - val_accuracy: 0.1430\n",
      "Epoch 7/10\n",
      "3130/3130 [==============================] - 152s 49ms/step - loss: 11.5144 - accuracy: 0.1414 - val_loss: 11.9642 - val_accuracy: 0.1400\n",
      "Epoch 8/10\n",
      "3130/3130 [==============================] - 165s 53ms/step - loss: 11.9421 - accuracy: 0.1376 - val_loss: 10.1512 - val_accuracy: 0.1396\n",
      "Epoch 9/10\n",
      "3130/3130 [==============================] - 166s 53ms/step - loss: 11.8890 - accuracy: 0.1393 - val_loss: 12.0568 - val_accuracy: 0.1399\n",
      "Epoch 10/10\n",
      "3130/3130 [==============================] - 159s 51ms/step - loss: 12.0729 - accuracy: 0.1399 - val_loss: 12.0188 - val_accuracy: 0.1401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21cb305c100>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=10,\n",
    "         validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bfd34e-bdde-4483-98ba-f77d9b9d3b14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yuuni",
   "language": "python",
   "name": "yuuni"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
